PSYCHOLOGISCHE DIAGNOSTIK MIT LLMs AUTOMATISIEREN
==================================================

Stand: 2026-01-24

QUELLEN
-------
  Web-Recherche durchgefuehrt am 2026-01-24:
  - sciencedirect.com (RAG-LLM on ICD-11 - LLMind Chat)
  - pmc.ncbi.nlm.nih.gov (GenAI in Mental Health Review)
  - jmir.org/mental (Mental Health AI Capabilities)
  - arxiv.org (Multi-Agent LLM Psychotherapy)
  - s10.ai (AI-Powered ICD-10 Documentation)
  - springer.com (AI Decision Support Mental Health)

DISCLAIMER
==========
  WICHTIG: LLM-basierte Diagnostik ersetzt NICHT:
    - Klinische Expertise
    - Fachliche Ausbildung
    - Therapeutische Beziehung
    - Ethische Verantwortung

  Einsatz nur als DECISION SUPPORT, nicht als Diagnose-Tool!

GRUNDPRINZIP
============
  LLM-basierte diagnostische Unterstuetzung:
    1. Adaptive Fragebogen-Generierung
    2. Symptom-Extraktion aus natuerlicher Sprache
    3. ICD-10/ICD-11 Klassifikations-Mapping
    4. Strukturierte Reports fuer Kliniker

ICD-10 vs ICD-11
================
  ICD-10 (International Classification of Diseases, 10th):
    - Aktuell weit verbreitet
    - Kapitel V: Psychische Stoerungen (F00-F99)

  ICD-11 (aktueller Standard seit 2022):
    - Modernere Klassifikation
    - Bessere digitale Struktur
    - Dimensional statt kategorial

LLMIND CHAT (FORSCHUNG)
=======================
  Konzept:
    - RAG-Modell mit Gemma 2 LLM
    - ICD-11 als Knowledge Base
    - Diagnostische Entscheidungsunterstuetzung

  Evaluierung:
    - Getestet gegen DSM-5-TR klinische Faelle
    - Reliable Decision Support
    - Reduziert Misklassifikationen

  Technologie:
    - Retrieval-Augmented Generation
    - Real-time ICD-11 Zugriff
    - Kontextbasierte Antworten

EVIDENZLAGE (STAND 2025)
========================
  Gemischte Ergebnisse:
    - GPT-4 uebertrifft Zufallsniveau bei Patientenidentifikation
    - Bard: 88.6% True-Positive Rate bei Alzheimer
    - GPT-4 vermeidet klare Diagnosen
    - Bard: Haeufige Fehldiagnosen mit hoher Konfidenz

  Staerken:
    - Psychoedukation
    - Emotional Awareness

  Schwaechen:
    - Diagnostische Genauigkeit
    - Kulturelle Kompetenz
    - Emotionales Engagement

  Validierungsstatus:
    - Nur 21% in klinischer Validierung
    - 79% noch in explorativer Forschung
    - 71% moderate methodische Qualitaet

ADAPTIVE FRAGEBOGEN-SYSTEME
===========================
  AAP (Automated Assessment Paradigm):
    - Validierte Skalen (z.B. BDI) in LLM-Dialog
    - Adaptives Fragen basierend auf Antworten
    - Bessere User Experience

  Vorteile gegenueber klassischen Frageboegen:
    - NLP erfasst Kontext und Emotionen
    - Dimensionale Symptom-Darstellung
    - Adaptive Frage-Pfade
    - Natuerlichere Interaktion

MULTI-AGENT SYSTEME
===================
  Konzept (Forschung):
    - Simulierte Client-Profile
    - 10 Stoerungskategorien:
      * Adjustment Disorder
      * Anxiety
      * Bipolar Disorder
      * Depression
      * OCD
      * Panic Disorder
      * PTSD
      * Schizophrenia
      * Social Anxiety
      * Substance Abuse

  DSM-5 Fragebogen (13 Domains):
    - Depression, Anger, Mania
    - Anxiety, Somatic Symptoms
    - Suicidal Ideation, Psychosis
    - Sleep, Memory
    - Repetitive Thoughts/Behaviors
    - Dissociation
    - Personality Functioning
    - Substance Use

AI DECISION SUPPORT SYSTEMS
===========================
  NEPAR (Network Pattern Recognition):
    - Automatische Diagnose
    - Nur 28 Fragen (vs. traditionell mehr)
    - 89% Genauigkeit
    - Ohne menschlichen Input

  Anwendung:
    - Screening-Tools
    - Triage
    - Forschung

FRAGEBOGEN-GENERIERUNG MIT LLM
==============================
  Moeglicher Workflow:

  1. STOERUNGSBILD DEFINIEREN
     - ICD-10/11 Code auswaehlen
     - Relevante Symptome identifizieren

  2. ITEM-GENERIERUNG
     - LLM generiert Fragen zu Symptomen
     - Verschiedene Schweregrade

  3. VALIDIERUNG
     - Fachpersonal reviewt Items
     - Psychometrische Pruefung

  4. ADMINISTRATION
     - Adaptiv oder linear
     - Digital oder Paper

  Beispiel-Prompt:
  ----------------------------------------------------------------
  Generiere 10 Screening-Fragen fuer Depression (ICD-11).
  Orientiere dich an validierten Instrumenten (BDI, PHQ-9).
  Format: Frage + 4-stufige Likert-Skala
  ----------------------------------------------------------------

ETHISCHE UND RECHTLICHE ASPEKTE
===============================
  Bedenken:
    - Vertrauenswuerdigkeit von AI-Output
    - Genauigkeit kritisch bei Diagnosen
    - Kulturelle Bias in Training Data
    - Datenschutz (sensible Gesundheitsdaten)

  Regulierung:
    - EU AI Act: Gesundheits-AI = High-Risk
    - DSGVO: Besondere Kategorien personenbezogener Daten
    - Berufsordnung: Diagnose durch Fachpersonal

RISIKEN
=======
  - Instabiler Output (verschiedene Antworten)
  - Halluzinationen
  - Ethische und rechtliche Risiken
  - Datenschutz und Sicherheit
  - Mangelnde emotionale Verbindung
  - Fehlende Supervision

BEKANNTE FEHLER BEI LLM-DIAGNOSTIK
==================================
  GPT-4:
    - Vermeidet klare Diagnose-Aussagen
    - Eher konservativ/vorsichtig

  Gemini/Bard:
    - Macht Fehldiagnosen mit hoher Konfidenz
    - Bei komplexen Stoerungen (z.B. Narzissmus) unzuverlaessig

  Generell:
    - LLMs koennen bei komplexen Persoenlichkeitsstoerungen
      irrefuehrende Ergebnisse liefern
    - "Halluzinieren" von Diagnosen moeglich

SINNVOLLE LLM-ROLLE
===================
  LLMs sollten NICHT "frei diagnostizieren"!

  Stattdessen als Assistenz nutzen:
    - Standardisierte Frageboegen AUSFUELLEN helfen
    - Antworten AUSWERTEN helfen
    - Aber NICHT Diagnosen erfinden

  Best Practice:
    - LLM wertet strukturierte Antworten aus
    - Basierend auf validierten Scoring-Regeln
    - Output: Score + Empfehlung zur Abklaerung
    - NIEMALS: "Sie haben Depression"

BACH-INTEGRATION
================
  ACHTUNG: Nur fuer Forschung/Entwicklung, nicht klinisch!

  Empfohlener Workflow (BACH-spezifisch):
    1. PubMed Partner nutzen fuer Validierungsstudien
    2. Gemini fuer Fragenkatalog basierend auf Wissenschaft
    3. Ollama (lokal!) fuer Patientendaten-Auswertung
    4. Fachliche Review vor jeder Nutzung

  Partner-Zuweisung:
    - Partner 006 (PubMed): Aktuelle ICD-11 Studien laden
    - Gemini: Fragebogen basierend auf wissenschaftlichen Daten
    - Ollama: Auswertung (PFLICHT bei Patientendaten)
    - KEINE Cloud-LLMs fuer echte Patientendaten!

ANWENDUNGS-SZENARIEN
====================
  ERLAUBT:
    - Generierung von Fragebogen-Entwuerfen
    - Literatur-Review
    - Edukative Materialien
    - Anonymisierte Forschung

  NICHT ERLAUBT:
    - Direkte Diagnose-Stellung
    - Therapie ohne Fachperson
    - Unbeaufsichtigte Patienteninteraktion
    - Speicherung identifizierbarer Daten in Cloud

ZUKUNFTSAUSBLICK
================
  Trends:
    - Bessere Validierung von AI-Tools
    - Spezialisierte Mental Health LLMs
    - Integration in klinische Workflows
    - Regulatorische Frameworks

  Bis dahin:
    - Human-in-the-Loop IMMER erforderlich
    - AI als Werkzeug, nicht als Therapeut

SICHERHEITSHINWEISE
===================
  KRITISCH:
    - Niemals Patientendaten an Cloud-LLMs
    - Keine automatisierten Diagnosen
    - Fachperson muss final entscheiden
    - Dokumentation aller AI-Nutzung
    - Informierte Einwilligung bei Einsatz

SIEHE AUCH
==========
  wiki/automatisierung/dokumentation.txt
  wiki/ollama.txt
  wiki/datenschutz.txt (zu erstellen)
