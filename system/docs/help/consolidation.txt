# Portabilitaet: SYSTEM
# Zuletzt validiert: 2026-02-08
# Naechste Pruefung: 2026-05-08
# Ressourcen: [hub/consolidation.py, memory_consolidation table]

MEMORY-KONSOLIDIERUNG
=====================

STAND: 2026-02-08

WAS IST KONSOLIDIERUNG?
-----------------------
Konsolidierung ist der aktive Prozess, der aus Rohdaten (Sessions, Lessons,
Working Memory) Sinnstrukturen schafft und in Kontext überführt. 

Analog zum menschlichen Schlaf:
- Erlebnisse werden verarbeitet, Wichtiges behalten.
- Wiederholung stärkt Verbindungen (Boost), Ungenutztes verblasst (Decay).
- Zusammenfassung reduziert Details, behält die Essenz.

KONSOLIDIERUNGS-EBENEN (Pipeline)
---------------------------------

  ROHDATEN (Sessions, Working Mem) --[Analyse]--> ASM (Metadaten)
  ASM (Metadaten) --[KI-Review]--> ESSENZ (Lessons, Context)
  ESSENZ --[Indexierung]--> TRIGGER-DB (Assoziatives Gedächtnis)

TABELLEN (v1.1.80+ Aktiv)
-------------------------
  memory_sessions      Rohdaten (360+ Einträge)
  memory_lessons       Gereinigte Erkenntnisse (70+ Einträge)
  memory_consolidation Tracking & Scores (350+ Einträge)
  context_triggers     Assoziative Brücken (900+ Triggers)

CLI-BEFEHLE (bach consolidate)
------------------------------
  status       Zeigt Statistiken und fällige Konsolidierungen.
  run          Führt alle verfügbaren Konsolidierungs-Schritte aus (weight, archive, index, sync-triggers, forget).
  compress     Kompression von Sessions zu Context-Einträgen.
               --cleanup: Leere Sessions aufräumen
               --batch: Sessions nach Tag gruppieren
               --run: Vollständige Komprimierung mit Regelwerk
  weight       Aktualisierung der Relevanz-Scores (Decay/Boost).
  archive      Verschieben von veraltetem Wissen in das Langzeit-Archiv.
  index        Abgleich zwischen Fakten, Help und Wiki.
  review       Erstellt Review-Tasks für manuelle Validierung.
  init         Tracking für existierende Einträge initialisieren.
  sync-triggers Dynamische Kontext-Trigger aktualisieren (NEU v1.1.80).
  forget       Ungenutzte Einträge löschen (weight < threshold).
  reclassify   Falsch kategorisierte Einträge korrigieren (NEU v1.1.81).

DAEMON-INTEGRATION
------------------
Die Konsolidierung kann als Hintergrund-Job laufen (daemon_jobs):
- `consolidate-weight`: Täglich (Decay-Simulation).
- `consolidate-archive`: Wöchentlich (Archiv-Prüfung).
- `consolidate-index`: Facts-Index aktualisieren.

(Hinweis: Daemon-Jobs müssen konfiguriert werden - siehe docs/docs/docs/help/daemon.txt)

TRUTHFULNESS:
Jeder Konsolidierungslauf erzeugt Log-Einträge und bei Zweifeln 
Review-Tasks (#category: maintenance).

SIEHE AUCH
----------
  docs/docs/docs/help/memory.txt          Kognitives Gedaechtnis Modell
  docs/docs/docs/help/lessons.txt         Best Practices & Erkenntnisse
  docs/docs/docs/help/daemon.txt          Daemon-Jobs
  hub/consolidation.py     Implementation der Logik
  ARCHITECTURE.md          System-Architektur (Memory-Modell)

TEILPROZESSE (BEREITS VORHANDEN)
--------------------------------
Diese existierenden Tools sind Teil der Konsolidierung:

  tools/autolog_analyzer.py     Session-Analyse (ASM_003)
  tools/context_compressor.py   Komprimierung (ASM_004/005)
  skills/_protocols/wiki-*      Wiki-Autoren
  skills/_protocols/help-*      Help-Autoren

DATENBANK-SCHEMA
----------------
memory_consolidation (AKTIV, 350+ Eintraege):

  id                INTEGER PRIMARY KEY
  source_table      TEXT        -- memory_sessions, memory_lessons, etc.
  source_id         INTEGER     -- ID in Quelltabelle
  times_accessed    INTEGER     -- Abruf-Zaehler
  last_accessed     TIMESTAMP   -- Letzter Abruf
  weight            REAL        -- Relevanz-Score (0.0-1.0)
  decay_rate        REAL        -- Verfalls-Rate
  threshold         REAL        -- Archivierungs-Schwelle
  status            TEXT        -- active, archived, deleted
  consolidated_to   INTEGER     -- ID in memory_context (wenn konsolidiert)
  created_at        TIMESTAMP
  updated_at        TIMESTAMP

WORKFLOW: SESSION -> KONTEXT
----------------------------
1. Session endet (--shutdown)
2. autolog_analyzer.py extrahiert Aktivitaeten
3. context_compressor.py erstellt Zusammenfassung
4. Zusammenfassung in memory_sessions gespeichert
5. [DAEMON] Nach X Sessions: Komprimierung zu Context
6. [KI-REVIEW] Prueft Sinnstruktur, korrigiert
7. Ergebnis in memory_context mit Triggern

WORKFLOW: FACT -> WIKI/HELP
---------------------------
1. Neuer Fact wird erstellt: bach --memory fact "thema:wert"
2. consolidate-index prueft: Existiert Help/Wiki zu "thema"?
3. Falls nein: Task erstellen "Wiki-Eintrag zu [thema] erstellen"
4. Wiki-Autor erstellt Eintrag
5. Fact wird aktualisiert mit Pfad-Verweis

WORKFLOW: WIKI/HELP -> FACTS INDEX
----------------------------------
1. consolidate-index scannt docs/docs/docs/help/*.txt und wiki/*.txt
2. Fuer jeden Eintrag: Existiert Fact?
3. Falls nein: Fact erstellen als Index
   HELP.memory -> "Memory-System Dokumentation"
   WIKI.gemini -> "Google Gemini KI-Modelle"
4. Facts dienen als schneller Lookup

SCHWELLENWERTE (KONFIGURIERBAR)
-------------------------------
  weight_threshold_archive: 0.2   Unter diesem Wert: Archivieren
  weight_threshold_delete:  0.05  Unter diesem Wert: Loeschen
  decay_rate_default:       0.95  Taeglicher Verfall (5%)
  boost_on_access:          0.1   Gewichts-Erhoehung bei Abruf
  sessions_before_compress: 10    Sessions bis Komprimierung
  days_before_archive:      90    Tage bis Archivierung

NEUE OPERATIONEN (v1.1.80+)
---------------------------
  sync-triggers    Aktualisiert dynamische Trigger aus:
                   - workflow_trigger_generator.py
                   - lesson_trigger_generator.py
                   - tool_auto_discovery.py
                   - theme_packet_generator.py
                   - trigger_maintainer.py

  forget           Deaktiviert/loescht Eintraege mit weight < 0.05
                   - memory_lessons: is_active = 0
                   - memory_working: is_active = 0
                   - memory_facts: DELETE

  reclassify       Korrigiert falsche Kategorisierungen:
                   - Lesson -> Context (bei hoher Nutzung)
                   - Working -> Lesson (bei Lesson-Pattern)
                   - Working -> Fact (bei Key:Value Format)
                   - Fact ohne Wiki -> Task erstellen

                   Manuelle Konvertierung:
                     bach consolidate reclassify lesson 42 context

                   Automatische Analyse:
                     bach consolidate reclassify
                     bach consolidate reclassify --fix
